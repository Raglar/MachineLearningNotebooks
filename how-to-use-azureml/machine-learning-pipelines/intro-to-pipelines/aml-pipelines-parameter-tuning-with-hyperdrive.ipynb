{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-parameter-tuning-with-hyperdrive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure Machine Learning Pipeline with HyperDriveStep\n",
        "\n",
        "\n",
        "This notebook is used to demonstrate the use of HyperDriveStep in AML Pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites and Azure Machine Learning Basics\n",
        "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration Notebook](https://aka.ms/pl-config) first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc. \n",
        "\n",
        "## Azure Machine Learning and Pipeline SDK-specific imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.1.5\n"
        }
      ],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.environment import CondaDependencies\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\n",
        "from azureml.train.dnn import TensorFlow\n",
        "# from azureml.train.hyperdrive import *\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive import choice, loguniform\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import urllib\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize workspace\n",
        "\n",
        "Initialize a workspace object from persisted configuration. If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure the config file is present at .\\config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "avadevitsmlsvc\nRG-ITSMLTeam-Dev\nwestus2\nff2e23ae-7d7c-4cbd-99b8-116bb94dca6e\n"
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create an Azure ML experiment\n",
        "Let's create an experiment named \"tf-mnist\" and a folder to hold the training scripts. \n",
        "\n",
        "> The best practice is to use separate folders for scripts and its dependent files for each step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step. \n",
        "\n",
        "> The script runs will be recorded under the experiment in Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "script_folder = './tf-mnist'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "\n",
        "exp = Experiment(workspace=ws, name='Hyperdrive_sample')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download MNIST dataset\n",
        "In order to train on the MNIST dataset we will first need to download it from Yan LeCun's web site directly and save them in a `data` folder locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "('./data/mnist/test-labels.gz', <http.client.HTTPMessage at 0x163c2714fc8>)"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "os.makedirs('./data/mnist', exist_ok=True)\n",
        "\n",
        "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename = './data/mnist/train-images.gz')\n",
        "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename = './data/mnist/train-labels.gz')\n",
        "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename = './data/mnist/test-images.gz')\n",
        "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename = './data/mnist/test-labels.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show some sample images\n",
        "Let's load the downloaded compressed file into numpy arrays using some utility functions included in the `utils.py` library file from the current folder. Then we use `matplotlib` to plot 30 random images from the dataset along with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import load_data\n",
        "\n",
        "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the neural network converge faster.\n",
        "X_train = load_data('./data/mnist/train-images.gz', False) / 255.0\n",
        "y_train = load_data('./data/mnist/train-labels.gz', True).reshape(-1)\n",
        "\n",
        "X_test = load_data('./data/mnist/test-images.gz', False) / 255.0\n",
        "y_test = load_data('./data/mnist/test-labels.gz', True).reshape(-1)\n",
        "\n",
        "# count = 0\n",
        "# sample_size = 30\n",
        "# plt.figure(figsize = (16, 6))\n",
        "# for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
        "#     count = count + 1\n",
        "#     plt.subplot(1, sample_size, count)\n",
        "#     plt.axhline('')\n",
        "#     plt.axvline('')\n",
        "#     plt.text(x = 10, y = -10, s = y_train[i], fontsize = 18)\n",
        "#     plt.imshow(X_train[i].reshape(28, 28), cmap = plt.cm.Greys)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload MNIST dataset to blob datastore \n",
        "A [datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data) is a place where data can be stored that is then made accessible to a Run either by means of mounting or copying the data to the compute target. In the next step, we will use Azure Blob Storage and upload the training and test set into the Azure Blob datastore, which we will then later be mount on a Batch AI cluster for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 4 files\nUploading ./data/mnist\\test-images.gz\nUploading ./data/mnist\\test-labels.gz\nUploading ./data/mnist\\train-images.gz\nUploading ./data/mnist\\train-labels.gz\nUploaded ./data/mnist\\test-labels.gz, 1 files out of an estimated total of 4\nUploaded ./data/mnist\\train-labels.gz, 2 files out of an estimated total of 4\nUploaded ./data/mnist\\test-images.gz, 3 files out of an estimated total of 4\nUploaded ./data/mnist\\train-images.gz, 4 files out of an estimated total of 4\nUploaded 4 files\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_f5c13e50314544f9a045e3d1876f2890"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "ds = ws.get_default_datastore()\n",
        "ds.upload(src_dir='./data/mnist', target_path='mnist', overwrite=True, show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve or create a Azure Machine Learning compute\n",
        "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the training script on this compute target.\n",
        "\n",
        "If we could not find the compute with the given name in the previous cell, then we will create a new compute here. This process is broken down into the following steps:\n",
        "\n",
        "1. Create the configuration\n",
        "2. Create the Azure Machine Learning compute\n",
        "\n",
        "**This process will take a few minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating a new compute target...\nCreating\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\nAzure Machine Learning Compute attached\n"
        }
      ],
      "source": [
        "cluster_name = \"gpu-cluster\"\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target {}.'.format(cluster_name))\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
        "                                                               max_nodes=4)\n",
        "\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    compute_target.wait_for_completion(show_output=True, timeout_in_minutes=20)\n",
        "\n",
        "print(\"Azure Machine Learning Compute attached\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Copy the training files into the script folder\n",
        "The TensorFlow training script is already created for you. You can simply copy it into the script folder, together with the utility library used to load compressed data file into numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./tf-mnist\\\\utils.py'"
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# the training logic is in the tf_mnist.py file.\n",
        "shutil.copy('./tf_mnist.py', script_folder)\n",
        "\n",
        "# the utils.py just helps loading data from the downloaded MNIST dataset into numpy arrays.\n",
        "shutil.copy('./utils.py', script_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create TensorFlow estimator\n",
        "Next, we construct an [TensorFlow](https://docs.microsoft.com/python/api/azureml-train-core/azureml.train.dnn.tensorflow?view=azure-ml-py) estimator object.\n",
        "The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed -- if additional pip or conda packages are required, their names can be passed in via the `pip_packages` and `conda_packages` arguments and they will be included in the resulting docker.\n",
        "\n",
        "The TensorFlow estimator also takes a `framework_version` parameter -- if no version is provided, the estimator will default to the latest version supported by AzureML. Use `TensorFlow.get_supported_versions()` to get a list of all versions supported by your current SDK version or see the [SDK documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.dnn?view=azure-ml-py) for the versions supported in the most current release.\n",
        "\n",
        "The TensorFlow estimator also takes a `framework_version` parameter -- if no version is provided, the estimator will default to the latest version supported by AzureML. Use `TensorFlow.get_supported_versions()` to get a list of all versions supported by your current SDK version or see the [SDK documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.dnn?view=azure-ml-py) for the versions supported in the most current release."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "est = TensorFlow(source_directory=script_folder,                 \n",
        "                 compute_target=compute_target,\n",
        "                 entry_script='tf_mnist.py', \n",
        "                 use_gpu=True,\n",
        "                 framework_version='1.13')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intelligent hyperparameter tuning\n",
        "Now let's try hyperparameter tuning by launching multiple runs on the cluster. First let's define the parameter space using random sampling.\n",
        "\n",
        "In this example we will use random sampling to try different configuration sets of hyperparameters to maximize our primary metric, the best validation accuracy (`validation_acc`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "        '--batch-size': choice(25, 50, 100),\n",
        "        '--first-layer-neurons': choice(10, 50, 200, 300, 500),\n",
        "        '--second-layer-neurons': choice(10, 50, 200, 500),\n",
        "        '--learning-rate': loguniform(-6, -1)\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will define an early termnination policy. The `BanditPolicy` basically states to check the job every 2 iterations. If the primary metric (defined later) falls outside of the top 10% range, Azure ML terminate the job. This saves us from continuing to explore hyperparameters that don't show promise of helping reach our target metric.\n",
        "\n",
        "Refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-tune-hyperparameters#specify-an-early-termination-policy) for more information on the BanditPolicy and other policies available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are ready to configure a run configuration object, and specify the primary metric `validation_acc` that's recorded in your training runs. If you go back to visit the training script, you will notice that this value is being logged after every epoch (a full batch set). We also want to tell the service that we are looking to maximizing this value. We also set the number of samples to 20, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "hd_config = HyperDriveConfig(estimator=est, \n",
        "                             hyperparameter_sampling=ps,\n",
        "                             policy=early_termination_policy,\n",
        "                             primary_metric_name='validation_acc', \n",
        "                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                             max_total_runs=4,\n",
        "                             max_concurrent_runs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add HyperDrive as a step of pipeline\n",
        "\n",
        "### Setup an input for the hypderdrive step\n",
        "Let's setup a data reference for inputs of hyperdrive step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_folder = DataReference(\n",
        "    datastore=ds,\n",
        "    data_reference_name=\"mnist_data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HyperDriveStep\n",
        "HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n",
        "- **name:** Name of the step\n",
        "- **hyperdrive_config:** A HyperDriveConfig that defines the configuration for this HyperDrive run\n",
        "- **estimator_entry_script_arguments:** List of command-line arguments for estimator entry script\n",
        "- **inputs:** List of input port bindings\n",
        "- **outputs:** List of output port bindings\n",
        "- **metrics_output:** Optional value specifying the location to store HyperDrive run metrics as a JSON file\n",
        "- **allow_reuse:** whether to allow reuse\n",
        "- **version:** version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_output_name = 'metrics_output'\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                             datastore=ds)\n",
        "\n",
        "hd_step_name='hd_step01'\n",
        "hd_step = HyperDriveStep(\n",
        "    name=hd_step_name,\n",
        "    hyperdrive_config=hd_config,\n",
        "    estimator_entry_script_arguments=['--data-folder', data_folder],\n",
        "    inputs=[data_folder],\n",
        "    metrics_output=metrics_data,\n",
        "    allow_reuse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "conda_run_config = RunConfiguration(framework=\"python\")\n",
        "conda_run_config.target = compute_target\n",
        "cd = CondaDependencies.create(pip_packages=['pandas', 'azureml-defaults'], \n",
        "                              pin_sdk_version=True)\n",
        "conda_run_config.environment.python.conda_dependencies = cd\n",
        "\n",
        "best_run_data = PipelineData('best_run_data', is_directory=True, datastore=ds)\n",
        "\n",
        "best_run_step = PythonScriptStep(\n",
        "    name='get best run',\n",
        "    script_name='metrics.py',\n",
        "    compute_target=compute_target,\n",
        "        arguments=['--input_file', metrics_data,\n",
        "               '--output_dir', best_run_data],\n",
        "    inputs=[metrics_data],\n",
        "    outputs=[best_run_data],\n",
        "    runconfig=conda_run_config,\n",
        "    source_directory=os.path.join(os.getcwd(), 'metrics'),\n",
        "    allow_reuse=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step get best run [31954077][a9842d81-7995-43c1-bb55-df20aa92e1b0], (This step will run and generate new outputs)\nCreated step hd_step01 [7c9d2beb][d203a8c7-27ce-4ebf-8afc-30ef240e2a0f], (This step will run and generate new outputs)\nUsing data reference mnist_data for StepId [f338e5e0][c34f1c52-35c4-4553-a4fd-0ffa20b750c6], (Consumers of this data are eligible to reuse prior runs.)\nSubmitted PipelineRun 5e453cc5-031b-45b6-8144-1042c2ce1c66\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Hyperdrive_sample/runs/5e453cc5-031b-45b6-8144-1042c2ce1c66?wsid=/subscriptions/ff2e23ae-7d7c-4cbd-99b8-116bb94dca6e/resourcegroups/RG-ITSMLTeam-Dev/workspaces/avadevitsmlsvc\n"
        }
      ],
      "source": [
        "pipeline = Pipeline(workspace=ws, steps=[best_run_step])\n",
        "pipeline_run = exp.submit(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monitor using widget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wait for the completion of this Pipeline run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "6: Preparing\nccdb13a20bf2: Preparing\n9513cdf4e497: Preparing\n7f083f9454c0: Preparing\n29f36b5893dc: Preparing\n2af19136c6e4: Waiting\ne1171d4d60ca: Waiting\n6ef1a8ae63b7: Waiting\n85389f9ead9e: Waiting\nf2608f66a0e3: Waiting\n0e259b09e5f4: Waiting\n340dc32eb998: Waiting\ndf18b66efaa6: Waiting\nccdb13a20bf2: Waiting\n9513cdf4e497: Waiting\n7f083f9454c0: Waiting\n29f36b5893dc: Waiting\n5cc9db7391c3: Pushed\n9839507b53e9: Pushed\n6ada5d42555e: Pushed\n2af19136c6e4: Pushed\n8d30a00f5b79: Pushed\ne1171d4d60ca: Pushed\n6ef1a8ae63b7: Pushed\n\n340dc32eb998: Pushed\n0e259b09e5f4: Pushed\nccdb13a20bf2: Pushed\n9513cdf4e497: Pushed\nf2608f66a0e3: Pushed\n7f083f9454c0: Pushed\n85389f9ead9e: Pushed\n\n29f36b5893dc: Pushed\ndf18b66efaa6: Pushed\n63a5f7d0d524: Pushed\nlatest: digest: sha256:39923ba32e36cde922f2711479b1c0c01bbce539bd44311524f85a85d1c6e5b2 size: 3883\n2020/03/20 22:30:30 Successfully pushed image: avadevitsmlsvc4326118371.azurecr.io/azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc:latest\n2020/03/20 22:30:30 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 121.808230)\n2020/03/20 22:30:30 Populating digests for step ID: acb_step_0...\n2020/03/20 22:30:32 Successfully populated digests for step ID: acb_step_0\n2020/03/20 22:30:32 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 70.480194)\n2020/03/20 22:30:32 The following dependencies were found:\n2020/03/20 22:30:32 \n- image:\n    registry: avadevitsmlsvc4326118371.azurecr.io\n    repository: azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc\n    tag: latest\n    digest: sha256:39923ba32e36cde922f2711479b1c0c01bbce539bd44311524f85a85d1c6e5b2\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/base\n    tag: intelmpi2018.3-ubuntu16.04\n    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n  git: {}\n\nRun ID: cc11a was successful after 3m19s\n\nStreaming azureml-logs/55_azureml-execution-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt\n========================================================================================================================\n2020-03-20T22:36:22Z Starting output-watcher...\n2020-03-20T22:36:22Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc\na1298f4ce990: Pulling fs layer\n04a3282d9c4b: Pulling fs layer\n9b0d3db6dc03: Pulling fs layer\n8269c605f3f1: Pulling fs layer\n6504d449e70c: Pulling fs layer\n4e38f320d0d4: Pulling fs layer\nb0a763e8ee03: Pulling fs layer\n11917a028ca4: Pulling fs layer\na6c378d11cbf: Pulling fs layer\n6cc007ad9140: Pulling fs layer\n6c1698a608f3: Pulling fs layer\n365701db00b9: Pulling fs layer\n8269c605f3f1: Waiting\nb7ebcb59e975: Pulling fs layer\n6504d449e70c: Waiting\n6cc007ad9140: Waiting\n6c1698a608f3: Waiting\n11917a028ca4: Waiting\n365701db00b9: Waiting\nb7ebcb59e975: Waiting\n778e91aadd06: Pulling fs layer\n3a5b84c9b731: Pulling fs layer\n778e91aadd06: Waiting\n6046d078ceab: Pulling fs layer\n3a5b84c9b731: Waiting\na2fbf82f98cb: Pulling fs layer\n6046d078ceab: Waiting\na2fbf82f98cb: Waiting\n9b0d3db6dc03: Verifying Checksum\n9b0d3db6dc03: Download complete\n04a3282d9c4b: Download complete\n8269c605f3f1: Verifying Checksum\n8269c605f3f1: Download complete\na1298f4ce990: Verifying Checksum\na1298f4ce990: Download complete\n4e38f320d0d4: Verifying Checksum\n4e38f320d0d4: Download complete\n6504d449e70c: Verifying Checksum\n6504d449e70c: Download complete\nb0a763e8ee03: Verifying Checksum\nb0a763e8ee03: Download complete\n11917a028ca4: Verifying Checksum\n11917a028ca4: Download complete\n6c1698a608f3: Verifying Checksum\n6c1698a608f3: Download complete\n365701db00b9: Verifying Checksum\n365701db00b9: Download complete\n6cc007ad9140: Verifying Checksum\n6cc007ad9140: Download complete\nb7ebcb59e975: Verifying Checksum\nb7ebcb59e975: Download complete\n3a5b84c9b731: Verifying Checksum\n3a5b84c9b731: Download complete\n778e91aadd06: Verifying Checksum\n778e91aadd06: Download complete\na2fbf82f98cb: Verifying Checksum\na2fbf82f98cb: Download complete\na6c378d11cbf: Verifying Checksum\na6c378d11cbf: Download complete\na1298f4ce990: Pull complete\n04a3282d9c4b: Pull complete\n6046d078ceab: Verifying Checksum\n6046d078ceab: Download complete\n9b0d3db6dc03: Pull complete\n8269c605f3f1: Pull complete\n6504d449e70c: Pull complete\n4e38f320d0d4: Pull complete\nb0a763e8ee03: Pull complete\n11917a028ca4: Pull complete\na6c378d11cbf: Pull complete\n6cc007ad9140: Pull complete\n6c1698a608f3: Pull complete\n365701db00b9: Pull complete\nb7ebcb59e975: Pull complete\n778e91aadd06: Pull complete\n3a5b84c9b731: Pull complete\n6046d078ceab: Pull complete\na2fbf82f98cb: Pull complete\nDigest: sha256:39923ba32e36cde922f2711479b1c0c01bbce539bd44311524f85a85d1c6e5b2\nStatus: Downloaded newer image for avadevitsmlsvc4326118371.azurecr.io/azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc:latest\nd2b7736a45a744c1645125ff3aa7e93c2a07bf6a5862cd90aa76ec50cc640f4c\n2020/03/20 22:36:53 Version: 3.0.01160.0001 Branch: master Commit: 6b1e6e76\n2020/03/20 22:36:54 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2020/03/20 22:36:54 sshd runtime has already been installed in the container\nssh-keygen: /azureml-envs/azureml_38d0f964f8839a139fe2ea03eae0a41c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\nssh-keygen: /azureml-envs/azureml_38d0f964f8839a139fe2ea03eae0a41c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n\nStreaming azureml-logs/65_job_prep-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt\n===============================================================================================================\nStarting job preparation. Current time:2020-03-20T22:37:01.425555\nExtracting the control code.\nfetching and extracting the control code on master node.\nRetrieving project from snapshot: 74886beb-16c1-4b97-a629-cff375658ebb\nStarting the daemon thread to refresh tokens in background for process with pid = 99\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\nStarting the daemon thread to refresh tokens in background for process with pid = 159\nEntering Run History Context Manager.\nPreparing to call script [ metrics.py ] with arguments: ['--input_file', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/85137794-dcca-4b44-9d19-65470c5584bd/metrics_data', '--output_dir', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/best_run_data']\nAfter variable expansion, calling script [ metrics.py ] with arguments: ['--input_file', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/85137794-dcca-4b44-9d19-65470c5584bd/metrics_data', '--output_dir', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/best_run_data']\n\nall args: \n{'input_file': '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/85137794-dcca-4b44-9d19-65470c5584bd/metrics_data',\n 'output_dir': '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/best_run_data'}\ncwd: /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7\ndir of cwd ['metrics.py', 'logs', 'extract_project.success', 'azureml_compute_logs', 'azureml-setup', 'AZ_BATCHAI_STDOUTERR_DIR', 'azureml-logs', 'best_run_data', 'outputs']\ninput_dir_parent: /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/85137794-dcca-4b44-9d19-65470c5584bd\ndir of input_dir_parent: ['metrics_data']\ninput file: /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/85137794-dcca-4b44-9d19-65470c5584bd/metrics_data\nsaving hyperdrive_metrics_OG.csv to /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/best_run_data\nsaving hyperdrive_metrics_OG.csv to ./outputs\n                        HD_bc8756f0-2b44-4585-b382-591ae6c5d549_0  ...          HD_bc8756f0-2b44-4585-b382-591ae6c5d549_3\ntraining_acc    [1, 1, 1, 1, 1, 1, 0.9599999785423279, 1, 1, 1...  ...  [1, 1, 1, 1, 1, 0.9800000190734863, 1, 1, 1, 1...\nvalidation_acc  [0.9553999900817871, 0.9632999897003174, 0.970...  ...  [0.9519000053405762, 0.9581000208854675, 0.960...\nfinal_acc                                    [0.9807999730110168]  ...                               [0.9718999862670898]\n\n[3 rows x 4 columns]\nsaving hyperdrive_metrics.csv to /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/mounts/workspaceblobstore/azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/best_run_data\nsaving hyperdrive_metrics.csv to ./outputs\n                                       index  ...  final_acc\n0  HD_bc8756f0-2b44-4585-b382-591ae6c5d549_0  ...     0.9808\n1  HD_bc8756f0-2b44-4585-b382-591ae6c5d549_1  ...     0.9833\n2  HD_bc8756f0-2b44-4585-b382-591ae6c5d549_2  ...     0.9322\n3  HD_bc8756f0-2b44-4585-b382-591ae6c5d549_3  ...     0.9719\n\n[4 rows x 4 columns]\n\n\nThe experiment completed successfully. Finalizing run...\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n2 items cleaning up...\nCleanup took 0.13146185874938965 seconds\nStarting the daemon thread to refresh tokens in background for process with pid = 159\n\nStreaming azureml-logs/75_job_post-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt\n===============================================================================================================\nStarting job release. Current time:2020-03-20T22:37:15.084294\nLogging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 191\nJob release is complete. Current time:2020-03-20T22:37:18.468851\n\nStepRun(get best run) Execution Summary\n========================================\nStepRun( get best run ) Status: Finished\n\nWarnings:\nThis compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\n{'runId': 'd9c09f44-a18b-4f38-bb53-8530e8b173a7', 'target': 'gpu-cluster', 'status': 'Completed', 'startTimeUtc': '2020-03-20T22:36:20.123602Z', 'endTimeUtc': '2020-03-20T22:37:30.648659Z', 'warnings': [{'message': \"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\"}], 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '74886beb-16c1-4b97-a629-cff375658ebb', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '5e453cc5-031b-45b6-8144-1042c2ce1c66', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'metrics.py', 'useAbsolutePath': False, 'arguments': ['--input_file', '$AZUREML_DATAREFERENCE_metrics_data', '--output_dir', '$AZUREML_DATAREFERENCE_best_run_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'metrics_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/85137794-dcca-4b44-9d19-65470c5584bd/metrics_data', 'pathOnCompute': None, 'overwrite': False}, 'best_run_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d9c09f44-a18b-4f38-bb53-8530e8b173a7/best_run_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment Hyperdrive_sample Environment', 'version': 'Autosave_2020-03-20T22:26:56Z_0412ec32', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['pandas', 'azureml-defaults']}], 'name': 'azureml_38d0f964f8839a139fe2ea03eae0a41c'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=RNqXHvyNBcj03yf8jb%2Bg4%2BBtBA%2F5bESbocosRB8WYic%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/55_azureml-execution-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt?sv=2019-02-02&sr=b&sig=UiMxF6sDZc9qq26yX9GSoMCuI50rjntvt2hcNJfUirk%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'azureml-logs/65_job_prep-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/65_job_prep-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt?sv=2019-02-02&sr=b&sig=MKAxg2hClR3n9Oo26iAwt2DPDE3gVLEqhCHVYBAPwlI%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=b6N%2Bj%2FNe8f1OCwkS9NdhaNWHAtWxPJU931bDcAWaW0w%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'azureml-logs/75_job_post-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/75_job_post-tvmps_2473c2e304cb139521834e6efa81cf68c73009a7cf3e3d5d9fc24342d9c04159_d.txt?sv=2019-02-02&sr=b&sig=WvhKd4x8VvjwPZ%2Fd%2BXTfkQsq%2FYDGrdfQ8QiW%2FKdPqxk%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'azureml-logs/process_info.json': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=kOL5uzM2dVtkBpNocrPlN32LHtqKnQ3E4Z7qQUKM6Yw%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'azureml-logs/process_status.json': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=rSLxreoXm4evkyFXlwf2pB%2Fc8iAECpEbbO3mlirdt2g%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'logs/azureml/159_azureml.log': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/logs/azureml/159_azureml.log?sv=2019-02-02&sr=b&sig=IB14UsQAE3NEv1m0JVjjTnhag7T21M18CGN8%2F3932%2BY%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=GKuLajrJGna4oS8X9DVpTaVDbrfAI2vVX0Q2jPB0ifc%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=5dOXZIXiBiiIZviGz3eYxEIBRYpapu68Mh%2FevCHUoFU%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=YNOa0hQJnYLJkB4jX%2FljKFaZjijzCMl6iez%2FW6%2BPpig%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=5Q5ZMtRPeW2rHMPgo3NsugGGz0XuL6uWac1R6a4R0yA%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.d9c09f44-a18b-4f38-bb53-8530e8b173a7/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=%2BdGCceTYjD4JkegoxOLRzIRUfzAV52kUrBV1WCnGdQA%3D&st=2020-03-20T22%3A27%3A36Z&se=2020-03-21T06%3A37%3A36Z&sp=r'}}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '5e453cc5-031b-45b6-8144-1042c2ce1c66', 'status': 'Completed', 'startTimeUtc': '2020-03-20T22:17:30.920791Z', 'endTimeUtc': '2020-03-20T22:37:35.39317Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.5e453cc5-031b-45b6-8144-1042c2ce1c66/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=VIPiLBcDyFOCzhD1VExyo8fLw1JpB%2FHP7ZHZPgllAXA%3D&st=2020-03-20T22%3A27%3A38Z&se=2020-03-21T06%3A37%3A38Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.5e453cc5-031b-45b6-8144-1042c2ce1c66/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=nd95FvnWbNSxvfNS4MbgO1sVeV6R3lAnupB0Ii%2F%2BMSw%3D&st=2020-03-20T22%3A27%3A38Z&se=2020-03-21T06%3A37%3A38Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.5e453cc5-031b-45b6-8144-1042c2ce1c66/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=rYPVm4xnXVNdAddNrkHSF2r%2F6AOQ36Xd6mHfbM%2BkWTQ%3D&st=2020-03-20T22%3A27%3A38Z&se=2020-03-21T06%3A37%3A38Z&sp=r'}}\n\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pipeline_run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the\n",
        "\n",
        "`Created step hd_step01 [7c9d2beb][d203a8c7-27ce-4ebf-8afc-30ef240e2a0f], (This step will run and generate new outputs)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step get best run [31c67e94][a9842d81-7995-43c1-bb55-df20aa92e1b0], (This step is eligible to reuse a previous run's output)\nCreated step hd_step01 [54aa5211][a10bf668-d90f-44a4-9524-8759d419aa95], (This step will run and generate new outputs)\nUsing data reference mnist_data for StepId [e4f91bb0][c34f1c52-35c4-4553-a4fd-0ffa20b750c6], (Consumers of this data are eligible to reuse prior runs.)\nSubmitted PipelineRun 4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Hyperdrive_sample/runs/4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f?wsid=/subscriptions/ff2e23ae-7d7c-4cbd-99b8-116bb94dca6e/resourcegroups/RG-ITSMLTeam-Dev/workspaces/avadevitsmlsvc\n"
        }
      ],
      "source": [
        "pipeline = Pipeline(workspace=ws, steps=[best_run_step])\n",
        "pipeline_run = exp.submit(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note its the same story again\n",
        "\n",
        "`Created step hd_step01 [54aa5211][a10bf668-d90f-44a4-9524-8759d419aa95], (This step will run and generate new outputs)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " Running\n\n\nStepRunId: 966635a6-227c-48b4-8a79-14bfc751dddd\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Hyperdrive_sample/runs/966635a6-227c-48b4-8a79-14bfc751dddd?wsid=/subscriptions/ff2e23ae-7d7c-4cbd-99b8-116bb94dca6e/resourcegroups/RG-ITSMLTeam-Dev/workspaces/avadevitsmlsvc\nStepRun( hd_step01 ) Status: NotStarted\nStepRun( hd_step01 ) Status: Running\n\nStepRun(hd_step01) Execution Summary\n=====================================\nStepRun( hd_step01 ) Status: Finished\n{'runId': '966635a6-227c-48b4-8a79-14bfc751dddd', 'status': 'Completed', 'startTimeUtc': '2020-03-20T22:39:23.978593Z', 'endTimeUtc': '2020-03-20T22:49:51.892284Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'fc1a41b8-5804-42db-9886-92784784c69e', 'StepType': 'HyperDriveStep', 'ComputeTargetType': 'HyperDrive', 'azureml.pipelinerunid': '4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.966635a6-227c-48b4-8a79-14bfc751dddd/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=QmOdcszbao8MlZDTOc9xsXj6zNrNTlMYWFmsWsYrmgQ%3D&st=2020-03-20T22%3A39%3A53Z&se=2020-03-21T06%3A49%3A53Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.966635a6-227c-48b4-8a79-14bfc751dddd/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Dmi2%2FJwIovFOysupuxos8gJYOpeMSwOvcUjGYglLAW8%3D&st=2020-03-20T22%3A39%3A53Z&se=2020-03-21T06%3A49%3A53Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.966635a6-227c-48b4-8a79-14bfc751dddd/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=lQ5WFmz6KEVWL8iB972cXzMbS8etET6aDiyzD5bHW1A%3D&st=2020-03-20T22%3A39%3A53Z&se=2020-03-21T06%3A49%3A53Z&sp=r'}}\n\n\n\n\nStepRunId: 85fe6851-98a0-4898-b41b-34f54e6d725e\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Hyperdrive_sample/runs/85fe6851-98a0-4898-b41b-34f54e6d725e?wsid=/subscriptions/ff2e23ae-7d7c-4cbd-99b8-116bb94dca6e/resourcegroups/RG-ITSMLTeam-Dev/workspaces/avadevitsmlsvc\nStepRun( get best run ) Status: NotStarted\nStepRun( get best run ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt\n========================================================================================================================\n2020-03-20T22:50:36Z Starting output-watcher...\n2020-03-20T22:50:36Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc\na1298f4ce990: Pulling fs layer\n04a3282d9c4b: Pulling fs layer\n9b0d3db6dc03: Pulling fs layer\n8269c605f3f1: Pulling fs layer\n6504d449e70c: Pulling fs layer\n4e38f320d0d4: Pulling fs layer\nb0a763e8ee03: Pulling fs layer\n11917a028ca4: Pulling fs layer\na6c378d11cbf: Pulling fs layer\n6cc007ad9140: Pulling fs layer\n6c1698a608f3: Pulling fs layer\n365701db00b9: Pulling fs layer\nb7ebcb59e975: Pulling fs layer\n778e91aadd06: Pulling fs layer\n3a5b84c9b731: Pulling fs layer\n6046d078ceab: Pulling fs layer\na2fbf82f98cb: Pulling fs layer\n8269c605f3f1: Waiting\n6504d449e70c: Waiting\n11917a028ca4: Waiting\n4e38f320d0d4: Waiting\na6c378d11cbf: Waiting\nb0a763e8ee03: Waiting\n6cc007ad9140: Waiting\n6c1698a608f3: Waiting\nb7ebcb59e975: Waiting\n365701db00b9: Waiting\n3a5b84c9b731: Waiting\n6046d078ceab: Waiting\na2fbf82f98cb: Waiting\n9b0d3db6dc03: Verifying Checksum\n04a3282d9c4b: Download complete\n8269c605f3f1: Download complete\n4e38f320d0d4: Verifying Checksum\n4e38f320d0d4: Download complete\na1298f4ce990: Verifying Checksum\na1298f4ce990: Download complete\nb0a763e8ee03: Verifying Checksum\nb0a763e8ee03: Download complete\n6504d449e70c: Verifying Checksum\n6504d449e70c: Download complete\n11917a028ca4: Verifying Checksum\n11917a028ca4: Download complete\n6c1698a608f3: Download complete\n6cc007ad9140: Verifying Checksum\n6cc007ad9140: Download complete\nb7ebcb59e975: Download complete\n365701db00b9: Verifying Checksum\n365701db00b9: Download complete\n778e91aadd06: Verifying Checksum\n778e91aadd06: Download complete\n3a5b84c9b731: Verifying Checksum\n3a5b84c9b731: Download complete\na6c378d11cbf: Verifying Checksum\na6c378d11cbf: Download complete\na2fbf82f98cb: Verifying Checksum\na2fbf82f98cb: Download complete\na1298f4ce990: Pull complete\n04a3282d9c4b: Pull complete\n9b0d3db6dc03: Pull complete\n8269c605f3f1: Pull complete\n6046d078ceab: Verifying Checksum\n6046d078ceab: Download complete\n6504d449e70c: Pull complete\n4e38f320d0d4: Pull complete\nb0a763e8ee03: Pull complete\n11917a028ca4: Pull complete\na6c378d11cbf: Pull complete\n6cc007ad9140: Pull complete\n6c1698a608f3: Pull complete\n365701db00b9: Pull complete\nb7ebcb59e975: Pull complete\n778e91aadd06: Pull complete\n3a5b84c9b731: Pull complete\n6046d078ceab: Pull complete\na2fbf82f98cb: Pull complete\nDigest: sha256:39923ba32e36cde922f2711479b1c0c01bbce539bd44311524f85a85d1c6e5b2\nStatus: Downloaded newer image for avadevitsmlsvc4326118371.azurecr.io/azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc:latest\n0a1b244917a4d1fd3e92fc99a1ea2c5789988ef3ad1ff800fde838898c93198d\n2020/03/20 22:51:08 Version: 3.0.01160.0001 Branch: master Commit: 6b1e6e76\n2020/03/20 22:51:09 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2020/03/20 22:51:09 sshd runtime has already been installed in the container\nssh-keygen: /azureml-envs/azureml_38d0f964f8839a139fe2ea03eae0a41c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\nssh-keygen: /azureml-envs/azureml_38d0f964f8839a139fe2ea03eae0a41c/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n\nStreaming azureml-logs/65_job_prep-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt\n===============================================================================================================\nStarting job preparation. Current time:2020-03-20T22:51:17.436037\nExtracting the control code.\nfetching and extracting the control code on master node.\nRetrieving project from snapshot: 74886beb-16c1-4b97-a629-cff375658ebb\nStarting the daemon thread to refresh tokens in background for process with pid = 99\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\nStarting the daemon thread to refresh tokens in background for process with pid = 159\nEntering Run History Context Manager.\nPreparing to call script [ metrics.py ] with arguments: ['--input_file', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/966635a6-227c-48b4-8a79-14bfc751dddd/metrics_data', '--output_dir', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/best_run_data']\nAfter variable expansion, calling script [ metrics.py ] with arguments: ['--input_file', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/966635a6-227c-48b4-8a79-14bfc751dddd/metrics_data', '--output_dir', '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/best_run_data']\n\nall args: \n{'input_file': '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/966635a6-227c-48b4-8a79-14bfc751dddd/metrics_data',\n 'output_dir': '/mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/best_run_data'}\ncwd: /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e\ndir of cwd ['logs', 'metrics.py', 'azureml_compute_logs', 'azureml-setup', 'extract_project.success', 'AZ_BATCHAI_STDOUTERR_DIR', 'azureml-logs', 'best_run_data', 'outputs']\ninput_dir_parent: /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/966635a6-227c-48b4-8a79-14bfc751dddd\ndir of input_dir_parent: ['metrics_data']\ninput file: /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/966635a6-227c-48b4-8a79-14bfc751dddd/metrics_data\nsaving hyperdrive_metrics_OG.csv to /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/best_run_data\nsaving hyperdrive_metrics_OG.csv to ./outputs\n                        HD_18c73c77-8d9d-460b-b5a7-46e69a5b7d12_0  ...          HD_18c73c77-8d9d-460b-b5a7-46e69a5b7d12_3\ntraining_acc    [0.9800000190734863, 1, 1, 1, 1, 1, 1, 1, 1, 1...  ...  [0.9599999785423279, 1, 1, 0.9800000190734863,...\nvalidation_acc  [0.9560999870300293, 0.9599000215530396, 0.967...  ...  [0.9322999715805054, 0.9459999799728394, 0.959...\nfinal_acc                                    [0.9832000136375427]  ...                               [0.9803000092506409]\n\n[3 rows x 4 columns]\nsaving hyperdrive_metrics.csv to /mnt/batch/tasks/shared/LS_root/jobs/avadevitsmlsvc/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/mounts/workspaceblobstore/azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/best_run_data\nsaving hyperdrive_metrics.csv to ./outputs\n                                       index  ...  final_acc\n0  HD_18c73c77-8d9d-460b-b5a7-46e69a5b7d12_0  ...     0.9832\n1  HD_18c73c77-8d9d-460b-b5a7-46e69a5b7d12_1  ...     0.9548\n2  HD_18c73c77-8d9d-460b-b5a7-46e69a5b7d12_2  ...     0.9757\n3  HD_18c73c77-8d9d-460b-b5a7-46e69a5b7d12_3  ...     0.9803\n\n[4 rows x 4 columns]\n\n\nThe experiment completed successfully. Finalizing run...\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n2 items cleaning up...\nCleanup took 0.2686452865600586 seconds\nStarting the daemon thread to refresh tokens in background for process with pid = 159\n\nStreaming azureml-logs/75_job_post-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt\n===============================================================================================================\nStarting job release. Current time:2020-03-20T22:51:31.447688\nLogging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 191\nJob release is complete. Current time:2020-03-20T22:51:33.176443\n\nStepRun(get best run) Execution Summary\n========================================\nStepRun( get best run ) Status: Finished\n\nWarnings:\nThis compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\n{'runId': '85fe6851-98a0-4898-b41b-34f54e6d725e', 'target': 'gpu-cluster', 'status': 'Completed', 'startTimeUtc': '2020-03-20T22:50:36.100928Z', 'endTimeUtc': '2020-03-20T22:51:45.658348Z', 'warnings': [{'message': \"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\"}], 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '74886beb-16c1-4b97-a629-cff375658ebb', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_3f9cdf0ac8964f43b11558b4296c26fc', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'metrics.py', 'useAbsolutePath': False, 'arguments': ['--input_file', '$AZUREML_DATAREFERENCE_metrics_data', '--output_dir', '$AZUREML_DATAREFERENCE_best_run_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'metrics_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/966635a6-227c-48b4-8a79-14bfc751dddd/metrics_data', 'pathOnCompute': None, 'overwrite': False}, 'best_run_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/85fe6851-98a0-4898-b41b-34f54e6d725e/best_run_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment Hyperdrive_sample Environment', 'version': 'Autosave_2020-03-20T22:26:56Z_0412ec32', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['pandas', 'azureml-defaults']}], 'name': 'azureml_38d0f964f8839a139fe2ea03eae0a41c'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/azureml-logs/55_azureml-execution-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt?sv=2019-02-02&sr=b&sig=3idT1U272GXE%2BGFkpwBrKxgk0NXdZz%2FA5d009ZjZ9qg%3D&st=2020-03-20T22%3A41%3A51Z&se=2020-03-21T06%3A51%3A51Z&sp=r', 'azureml-logs/65_job_prep-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/azureml-logs/65_job_prep-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt?sv=2019-02-02&sr=b&sig=rzS%2BUPO32GixXAmTE%2FhpQFLritvgOrBdqykj%2Bbq1rlc%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=PZcN7KWVFotac20IAVTCh6Sk8NVvxIOs4MWRnJFtmtE%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'azureml-logs/75_job_post-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/azureml-logs/75_job_post-tvmps_f80e7c6e030031c7d218f196e77f39020afd22585978d75f084b3f804c264e03_d.txt?sv=2019-02-02&sr=b&sig=VwYTZk1uhQ%2F4f2lr0KkOctdYutAXNRtFeUm3hKc5bPA%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'azureml-logs/process_info.json': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=oRkCO%2FZvUxFTGtmRF1%2BOvD%2B7mqW%2FNMJ%2Fy84b2cPkuXY%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'azureml-logs/process_status.json': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=hiz9C9g%2FNAA5NOEfTT7qps2NAB9cE4ZzBAhLCkGrh%2Bw%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'logs/azureml/159_azureml.log': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/logs/azureml/159_azureml.log?sv=2019-02-02&sr=b&sig=P8WgTUYvoJM2gecZY%2FEzIPmAatWHJK5khIrs5nwWg5s%3D&st=2020-03-20T22%3A41%3A51Z&se=2020-03-21T06%3A51%3A51Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=0uqGAZED3xfe4ShQtaM%2FQgwh4uX9Z7iIkp4ZBuNn3KQ%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=F%2FpxXsoCGJE08nUQz2qLFbdJx5g5D%2BHypiS97J0XEqI%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=%2BXa8cpi6qgfWVKqswEobi66ZHyaRMnEQ3PtE8dziDnQ%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=%2BtVVwJCANVlyZ5MzeZMrqKAoSJR0eLOlef7rDSJeDsE%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.85fe6851-98a0-4898-b41b-34f54e6d725e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=kXgH8be7vwyn1pgxfLdavKbJw8fEmTsFlpe2sF8Btts%3D&st=2020-03-20T22%3A41%3A52Z&se=2020-03-21T06%3A51%3A52Z&sp=r'}}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f', 'status': 'Completed', 'startTimeUtc': '2020-03-20T22:39:20.247003Z', 'endTimeUtc': '2020-03-20T22:51:50.767551Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=k5rPcT86PzJ3%2F7CkWoM%2BAnRZmvPxoTi%2BJ60WCXO%2By%2Bc%3D&st=2020-03-20T22%3A41%3A53Z&se=2020-03-21T06%3A51%3A53Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Bq0sT6AX1rsjonv9CxTKrtGeCuUvTc%2FQFLUxYkvtyEU%3D&st=2020-03-20T22%3A41%3A53Z&se=2020-03-21T06%3A51%3A53Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://avadevitsmlsvc7139228118.blob.core.windows.net/azureml/ExperimentRun/dcid.4ab4b3b4-c6c4-424b-9cb2-4fc041ace64f/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=DLImC%2B2Ym5iQsyejl0Yl%2FXuIMw9fGsA4Ru%2B6N6E5ayA%3D&st=2020-03-20T22%3A41%3A53Z&se=2020-03-21T06%3A51%3A53Z&sp=r'}}\n\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "sanpil"
      }
    ],
    "category": "tutorial",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "Custom"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "Azure ML"
    ],
    "friendly_name": "Azure Machine Learning Pipeline with HyperDriveStep",
    "kernelspec": {
      "display_name": "Python (ret)",
      "language": "python",
      "name": "ret"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2-final"
    },
    "order_index": 8,
    "star_tag": [
      "featured"
    ],
    "tags": [
      "None"
    ],
    "task": "Demonstrates the use of HyperDriveStep"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}